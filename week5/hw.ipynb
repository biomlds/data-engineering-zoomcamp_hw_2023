{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2b8a64",
   "metadata": {},
   "source": [
    "\n",
    "In this homework we'll put what we learned about Spark in practice.\n",
    "\n",
    "For this homework we will be using the FHVHV 2021-06 data found here. [FHVHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd38e6",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "- 3.3.2\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4\n",
    "\n",
    "> <span style=\"color:red\">'3.3.2'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2930a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e95758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/27 04:09:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e8db6",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "We will use this dataset for all the remaining questions.</br>\n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.</br>\n",
    "\n",
    "\n",
    "- 2MB\n",
    "- 24MB\n",
    "- 100MB\n",
    "- 250MB\n",
    "\n",
    "> <span style=\"color:red\">24 MB</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff72b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhvhv_tripdata_2021-06.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45539a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(data_set = 'fhvhv_tripdata_2021-06.csv', schema=None, test=False):\n",
    "    \n",
    "    if test is True:\n",
    "        data_set = 'head.csv'\n",
    "    if schema is not None:\n",
    "        df = spark.read \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(data_set)\n",
    "    else:\n",
    "        df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(data_set)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe3f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47da2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c962895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14961892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6032981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a97b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fc65a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/06/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ccb42ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00003-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00001-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00002-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00000-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00004-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00007-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00005-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00006-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00008-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00009-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00010-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 user user 23M Feb 26 21:07 fhvhv/2021/06/part-00011-6ace8957-737c-412c-9806-6a9b98affc0e-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh fhvhv/2021/06/*.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3eab90",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15?</br></br>\n",
    "Consider only trips that started on June 15.</br>\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 50,982\n",
    "\n",
    "> <span style=\"color:red\">452470</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46faf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eb05197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70b7c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14961892"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d8732d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .filter(df.pickup_date == '2021-06-15') \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca2566",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>\n",
    "\n",
    "- 66.87 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours\n",
    "\n",
    "> <span style=\"color:red\">66.87</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "788dcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# def calc_trip_duration_in_h(pickup_datetime, dropoff_datetime):\n",
    "# #     delta = datetime.fromisoformat(dropoff_datetime) - datetime.fromisoformat(pickup_datetime)\n",
    "#     delta = dropoff_datetime - pickup_datetime\n",
    "#     return (delta.total_seconds()/3600)\n",
    "\n",
    "# trip_duration_udf = F.udf(calc_trip_duration, returnType=types.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9b3df45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_df(test=True)\n",
    "# p = df.select('pickup_datetime').take(1)[0].asDict()['pickup_datetime']\n",
    "# d = df.select('dropoff_datetime').take(1)[0].asDict()['dropoff_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5777144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.8788888888889"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeFmt = \"yyyy-MM-dd HH:mm:ss\"\n",
    "duration = ((F.unix_timestamp('dropoff_datetime', format=timeFmt)\n",
    "            - F.unix_timestamp('pickup_datetime', format=timeFmt))/3600)\n",
    "\n",
    "# df \\\n",
    "#     .withColumn('pickup_datetime', F.to_timestamp(df.pickup_datetime)) \\\n",
    "#     .withColumn('dropoff_datetime', F.to_timestamp(df.dropoff_datetime)) \\\n",
    "\n",
    "\n",
    "df = df.withColumn(\"Duration\", duration)\n",
    "max_duration = df.agg({\"Duration\": \"max\"}).collect()[0]\n",
    "max_duration[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb130c",
   "metadata": {},
   "source": [
    "\n",
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    " Sparkâ€™s User Interface which shows application's dashboard runs on which local port?</br>\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080\n",
    "\n",
    "> <span style=\"color:red\">4040</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a6c69",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)</br>\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- Crown Heights North\n",
    "\n",
    "> <span style=\"color:red\">Crown Heights North</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b6912673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv\t\t\t    get_data.sh  taxi+_zone_lookup.csv\ttets\r\n",
      "fhvhv_tripdata_2021-06.csv  head.csv\t taxi_zone_lookup.csv\tweek5.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c70d91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = read_df(data_set='taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c1733bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d699aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number',\n",
       " 'pickup_date',\n",
       " 'dropoff_date']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5c13643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LocationID='1'),\n",
       " Row(LocationID='2'),\n",
       " Row(LocationID='3'),\n",
       " Row(LocationID='4'),\n",
       " Row(LocationID='5')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones.select('LocationID').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cc52726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff6dc8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(PULocationID=196),\n",
       " Row(PULocationID=196),\n",
       " Row(PULocationID=196),\n",
       " Row(PULocationID=196),\n",
       " Row(PULocationID=196)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('PULocationID').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2a62de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = df.join(zones, zones.LocationID == df.PULocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "414b2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_counts = df_zones.groupBy(\"Zone\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd39693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               Zone| count|\n",
      "+-------------------+------+\n",
      "|Crown Heights North|231279|\n",
      "|           Union Sq|158937|\n",
      "|            Astoria|152493|\n",
      "|       East Chelsea|147673|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_zones_counts.filter(df_zones_counts.Zone.isin([\"East Chelsea\",\"Astoria\",\"Union Sq\", \"Crown Heights North\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60586c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
